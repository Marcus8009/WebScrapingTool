URL: https://www.microsoft.com/en-us/worklab/podcast/how-leaders-will-use-ai-to-unleash-creativity
Source: microsoft.com/worklab/podcast
Total Word Count: 7103

=== TRANSCRIPT CONTENT ===
Word Count: 3307

ELISE HU: This is WorkLab , the podcast from Microsoft. I’m your host, Elise Hu. On WorkLab , we hear from leading thinkers on the future of work—economists, designers, psychologists, technologists. They all share surprising data and explore the trends transforming the way we work. In this episode, we continue our exploration of large language model AI, or LLM AI.
JOHN MAEDA: Design today is going to play an important role in this LLM AI world, with the perspective on ethics. These kinds of ideas, which have been embedded in great products, are now going to have to be better than ever when it comes to this new kind of AI.
Hide full transcript
ELISE HU: On today’s show, John Maeda. John Maeda is a Vice President of Design and Artificial Intelligence at Microsoft, and in his richly varied career, he’s also been a professor, an author, a college president, and a business executive. His digital artwork, books, lectures, research, and teaching have explored how digital technology can empower creativity. So we have a wide-ranging chat today about this moment that we’re in for AI. So without further ado, my conversation with John Maeda.
ELISE HU: Thanks for coming on the show.
JOHN MAEDA: Glad to be here.
ELISE HU: And you recently made this big career move to join Microsoft.
JOHN MAEDA: Well, when I was in high school, I tried to apply for an internship at Microsoft and I didn’t get in. So luckily they didn’t ask me the same questions decades later, and I’m in.
ELISE HU: Well, welcome. There’s so much to talk about when it comes to AI, especially recent breakthroughs in large language models. It’s being called an inflection point. We’re hearing that a lot, or a Cambrian explosion. So why?
JOHN MAEDA: Well, I kind of chuckle when I keep reading things like inflection, Precambrian, or whatever. All these giant ways to say the whole world has shifted. I think it’s just the perfect example of the Moore’s Law effect, that the idea of doubling doesn’t seem like a big deal when it’s like one becomes two, two becomes four, four becomes eight, eight becomes 16. But the iteration, 30 or 40 of a Moore’s Law build—it’s like ketchup, the old kind of ketchup in the glass bottle where it just all plops out and you’re like, Whoa, where did this glob ketchup come from, because you’ve been holding the bottle over your head. The doubling feels very big.
ELISE HU: What are the implications?
JOHN MAEDA: Well, the implications are exciting because this technology is actually kind of useful. I think it introduces a new kind of scratch-your-head moment. Everything was command line based in the seventies and eighties: type in text and it does something for you. And then there was this graphic user interface boom, where suddenly you were able to use a mouse and use a computer. It was democratizing. Ironically, this means they’re going back to the command line, which is so interesting. But this is something that has been long foreseen, already a very common user experience pattern in China, for instance, with a WeChat world. So I think it was inevitable that we’d end up here.
ELISE HU: And when you mean that everything’s kind of returning to the command line, can you talk a little bit about that?
JOHN MAEDA: Well, I spent six years writing a book called How to Speak Machine , and the entire thesis was it’d be really good for people who don’t understand how computer science and AI works to understand the mechanics, the physics underneath it. And at the end of the book, I realized it wasn’t about how to speak machine, but how to speak human. Now we speak in natural language, English or whatever language you like. We’re speaking human to the machine.
ELISE HU: John Maeda, Wired magazine has said that Maeda is to design what Warren Buffett is to finance. I’m not going to ask you to have to, you know, respond to that particular quote, but I’d love to know, because you are so deeply embedded and considered a real leader in the designer community, how is the larger design community thinking about the potential and pitfalls of AI?
JOHN MAEDA: I feel that design today is going to play an important role in this LLM AI world, with the perspective on ethics, what matters. Trust. These kinds of ideas, which have been embedded in great products are now going to have to be better than ever when it comes to this new kind of AI. If you think of the Triangle of Engineering, product and design for technology products where, you know, product really has to carry that business role, has to make money, has to grow, preferably. And engineering is playing the role of, does it work or does it not work? Does the bridge stand by itself? Okay, it worked. Design tends to be stuck in a role where, like, is the bridge pretty enough, which is sometimes pretty important when you’re competing against other bridges. It also plays an important role in, does it look like it’s not going to fall down? And or, you know I just discovered that a certain kind of stone really is not good to take from the earth. Is this bridge made of that kind of stone? Then I actually don’t want to cross it. And I think that design cares about these dimensions. Not just the aesthetics, the beauty, but the aesthetics of the ethics inside any experience you encounter, in a way that a product person doesn’t have to care about as much and an engineer doesn’t have to care about as much. They care about it, but it isn’t in their ‘jobs to be done’ list.
ELISE HU: Huh. Well, let’s talk about some of these ethical concerns. What would you say are the questions that researchers, designers, companies grappling with AI and its potential—what needs to be worked out still most pressingly?
JOHN MAEDA: Well, there’s so many levels to that. You know, like, I’m creating the new design and tech report for South by Southwest, and I look back at the last nine years.
ELISE HU: Yeah.
JOHN MAEDA: In 2017, I noticed that Microsoft was really high-centered around responsible AI, inclusive design. And there’s one value that’s fairly simple but important, is the value of transparency, not like just see through, but do I understand it? And I think at a very basic level, understanding large language model AI, how it actually works, scientists are still trying to figure that out. But even for the general person to help them understand how it works is an important thing for design to do.
ELISE HU: How will people be able to use, beyond just these chatbots right now, but other programs to increase their creativity and their productivity?
JOHN MAEDA: Ah. In this age of AI, there’s a simple way to be less fearful of it. Ask yourself, What do you not actually like doing in your job? Like, gather all that information into a chart or summarize it for my boss. Versus, What do you want to really keep? There are things that I enjoyed doing—thinking about the strategy of something and how it might unfold. Think of ways to be able to do things 10 times faster than I ever thought possible, therefore, I can actually do 10x more. So on one hand, greater productivity because you’re doing what you are most productive and excited about. And also productivity, like, hey, I didn’t want to do that thing in the first place. So it’s all gone.
ELISE HU: I understand you have a metaphor you’ve been using, a scissors metaphor, to talk about AI. What is it?
JOHN MAEDA: Oh, well, you know, I held on to this thing from my early days of trying to understand artificial intelligence in the eighties. This work, from a person named Herbert Simon, he’s a Carnegie Mellon AI legend, but interestingly, he received a Nobel Prize in economics. And he had this phrase that always stuck with me about how the way to think of intelligence is, it’s two blades of a scissor. One blade of the scissors is cognition, and the other blade is context. And when you slice, slice, slice those two together, rub them together, it creates what feels like intelligence, which is what’s happened with large language model AI.
ELISE HU: It’s not just cognition that computers can handle now, it’s context.
JOHN MAEDA: Well, this amazing cognition blade arrived. And now we can just, like, rub context against it. Like, I could take the last eight things we said to each other—the context—rub it against the cognition blade and say, Hey, what did we talk about?
ELISE HU: Yeah, sum up the themes of our conversation.
JOHN MAEDA: It does that. A cognition blade is like, ready to go, boss. And the context is just pouring our information on top of it. And voila.
ELISE HU: Is AI capable of creativity itself, or does it just facilitate human creativity?
JOHN MAEDA: The best way I’ve heard this technology described is, it’s like a parrot, but it’s an awfully good parrot. It doesn’t just repeat back things you said to it, it can repeat back things that a lot of people in the world have said. So is it creative on its own? No. Can it make you more creative? Well, the answer is, every time you expose yourself to new information, do you get more creative? Yeah. So it’s a way to accelerate your own creativity.
ELISE HU: Well, we are asking a variety of people like you, experts in their field, as well as civilians, how they’re using AI in just their everyday lives. So what is it for you?
JOHN MAEDA: Well, as you discover how to leverage this odd technology, you find that, wow, that’s easy. Like, I always use Python, the programming language Python, to do things fast. Like, oh, I’ve got to sort this document this way, I’m going to write a Python code or whatever. Now, I just give it to the model and say, Hey, this is all the stuff I have, the context. Can you now categorize these things? And it’s like magic, voila. Or I’m trying to figure this thing out and I want 10 different perspectives, so can you be someone who’s a botanist? Can you be someone who is a shopkeeper? So it’s like running user research studies very quickly.
ELISE HU: Yeah.
JOHN MAEDA: With fictional people, they’re better than a persona, actually. You can talk with them.
ELISE HU: Oh, that’s interesting. Do you have kind of a dream scenario for where things look two to five years from now?
JOHN MAEDA: I think that we’re already seeing elements of how this model-based work that we do, whether the model is language-based or it’s image-based or interaction-based, it’s going to affect how we do things. When we make images or image with text or video, basically everything we do to communicate, I think it’s going to make it a lot easier for us to do the part that we usually only do if we’re not tired, you know? I mean, how many things have you made where you’re like, Oh my gosh, all this planning, here I go, do it. Okay, I did it. Well, I’m really tired. I don’t know what it’s going to be like, but I feel like I’m going to do the part that I actually thought I should be doing at the very end, but I got too tired.
ELISE HU: I feel like it could increase our body of knowledge too, right, to be able to see so many things in different ways or look around the corners that we were too tired to look around.
JOHN MAEDA: Oh, 100 percent. This whole list of things that we can do better, that I keep asking myself, What do I not like to do now? What can I Marie Kondo out of my brain? And now what if I had more time? What would I do instead?
ELISE HU: Yeah. Okay, so let’s talk a little bit about leaders of organizations and leadership. What should leaders, or what could they do, to harness this potential of AI, not just for themselves, but also for their teams?
JOHN MAEDA: I think what’s really powerful for leaders is the ability to listen broadly. Because the only way for leaders to listen right now, generally speaking, is through one-on-ones, which do not scale.
ELISE HU: Those are just their lieutenants, though, right? It’s not a foot soldier.
JOHN MAEDA: Well, you know, the good leaders skip levels and actually break the rules and, like, talk to everyone. I like those kinds of leaders because it creates individual bonds of trust, which means the organization can usually move faster because of that. However, it takes a lot of time. So, ultimately, you have the other choice, which is surveys. As we know, the best part of those surveys is the fill-in-the-blank part. In the past we only had word clouds, but now, bosses can talk to all of that feedback and say, Tell me about the time I let you all down. Tell me about the time that you felt really proud to be here. So it’s like doing Q&A, 24/7.
ELISE HU: Yeah. And the potential for being able to take those learnings and apply them, or change direction or come up with a new vision, are really endless.
JOHN MAEDA: It basically lets them save time to do the part that they probably were hired to do, but they could never do because the logistics of being able to communicate through a hierarchy are tremendous, as you know.
ELISE HU: Okay. More broadly, John, you have spoken a lot on what corporations and corporate leaders can learn from entrepreneurs or more scrappy start-ups. What can they learn?
JOHN MAEDA: I felt that there are these start-up companies and there are the grown-up companies. And the irony is that start-ups want to end up like the grown-ups, but, you know, the grown-ups are always like, Gee, I wish I was a start-up again. So I think that both can learn from each other. But the biggest thing one can learn from an entrepreneur is proximity to the customer, because it’s like a car with no walls, barely wheels. It’s got a jagged steering wheel. It’s like, Ouch. And the customer’s like, hey, I don’t like this, all the time. Whereas if you’re in a large corporation, you’re kind of like in an SUV or a bus or a jumbo jet. And so you really can’t feel the customer and how they are experiencing what you’re providing to them. So, learn from entrepreneurs how to listen to the customer, and that goes to the beauty of these new LLM AI systems. It means that the CEO or any different level of a corporation can actually begin to talk with customers, effectively, 24/7—understand what they’re thinking from all the customer support data that they get, which if I were a customer support professional, I would think, Wow, thank goodness it’s not just me hearing this. It’s my boss, my boss’s boss, my boss’s boss. Entrepreneurs are great with customers and that’s where they’ll learn.
ELISE HU: Okay, so for the listeners out there who are excited about the potential of AI and a lot of the things that we have talked about, where should they start?
JOHN MAEDA: Well, they should first start by trying this stuff out. I think that I have presented to a variety of audiences of all sizes, and I’ll ask, Hey, you know, who’s used this thing, ChatGPT, before? Who uses it every day? Like, who’s never heard of it? And ultimately, there are those who have not heard of it. The second thing is to break that transparency barrier, because what people are afraid of is they don’t really understand it at all. I like to point out that the only letter you have to care about in C-H-A-T G-P-T is the P. The P stands for pre-trained . So what that means is you’re getting out-of-the-box, powerful machine learning. As you know, in the old days, the only way to get AIML was to have a lot of data, because you had to train it. What’s different this time is, it comes pre-trained. It’s like a puppy that arrives, like able to do everything. And so you’re freaked out. You’re like, Whoa, this AI comes pre-trained? And then once you get over that cognitive hurdle, you discover it can do a lot of things you didn’t expect. And so, try it out. Learn from it. Learn how prompts work, learn how context works. Take the scissor blades and start snip, snip, snipping. I think the other thing that’s actionable is to help everyone in their organization understand that change is always a scary thing. And this is a change that really is a giant blob of ketchup coming out, maybe the whole bottle came out all at once. And so the next reaction is like, Hey, I don’t like ketchup. Ketchup is not good for you. You know, that kind of feeling. And so every organization should ask the question. Let’s first understand it. Let’s try it. Let’s learn what the cons list are, like, pros and cons. Let’s look at the pros and just kind of adapt as quickly as possible to what we want to use and what we don’t want to use. Because this technology is much like the world wide web’s emergence. I’m not sure if you were like me, but when someone showed me a homepage, I was like, Nah, never going to take off. Like a month and a half later, well, gotta build a homepage. So it’s like that, I think.
ELISE HU: John, you mentioned that you are neuroatypical, and so many folks out there are. So I’d love to know what potential you see for AI and accessibility.
JOHN MAEDA: Well, I like the fact that I can talk to it and share things, and I can ask it, Hey, can you make that more sense to the majority of people? And I think that it is a wonderful translator and interpreter of things. I’m also high on the autistic spectrum, so sometimes I can’t read emotion very well. So I can ask it to tell me, like, what does this mean? Like what’s the downlow? And that’s extremely helpful.
ELISE HU: I love that. Okay. Thanks so much.
JOHN MAEDA: Well, thanks for having me.
ELISE HU: Thanks again to John Maeda. I loved that conversation. And that’s it for this episode of the WorkLab podcast from Microsoft. Please subscribe and check back for the next episode. If you’ve got a question you’d like us to pose to leaders, drop us an email at worklab@microsoft.com. And check out the WorkLab digital publication, where you will find transcripts of all our episodes, along with thoughtful stories that explore the ways we work today. You can find all of it at Microsoft.com/WorkLab. As for this podcast, please rate us, review, and follow us wherever you listen. It helps us out. The WorkLab podcast is a place for experts to share their insights and opinions. WorkLab is produced by Microsoft with Godfrey Dadich Partners and Reasonable Volume. I’m your host, Elise Hu. Mary Melton is our correspondent. Sharon Kallander and Matthew Duncan produced this podcast. Jessica Voelker is the WorkLab editor. Okay, until next time.

=== PAGE PARAGRAPHS CONTENT ===
Word Count: 3796

Podcast

The Microsoft VP of Design and AI on the promise and potential of AI

WorkLab Guest John Meada

April 19, 2023

John Maeda is the Vice President of Design and Artificial Intelligence at Microsoft. In his richly varied career, he’s also been an artist, a professor, an author, a college president, and a business executive. His digital artwork, books, lectures, research, and teaching have explored how digital technology can empower creativity.

He joined WorkLab to discuss how everyone can best leverage the potential of AI to unleash creativity and reduce tedium and repetitive tasks.

Maeda is the third guest for season 4 of Microsoft’s WorkLab podcast, in which host Elise Hu has conversations with economists, designers, psychologists, and technologists who explore the data and insights into why and how work is changing.

Three big takeaways from this conversation:

One of the things Maeda is excited about is AI’s potential to minimize the time you spend on drudgery and rote tasks, and maximize the time you spend on engaging challenges. “Ask yourself: What do you not actually like doing in your job? What are things that you enjoy doing that you want to really keep? On the one hand, [AI will lead to] greater productivity because you’re doing what you are most excited about. And also, greater productivity because, hey, I didn’t want to do that other thing in the first place.”

What do scissors have to do with AI? Maeda cites an elegant metaphor that was first coined by legendary computer science professor Herbert Simon . “Imagine that there are two blades of a pair of scissors. One blade of the scissors is cognition, and the other blade is context. And when you slice, slice, slice, those two together, it creates what feels like intelligence. That’s what’s happening with large language model AI. This amazing new cognition blade has arrived, and now we can just, like, rub context against it.”

Maeda offers advice on how we can get a handle on the potential of AI: “Try it out. Learn how prompts work, learn how context works. Take the scissor blades and start snip, snip, snipping. Let’s first understand it. Let’s learn what the cons list are and just adapt as quickly as possible to what we want to use it for and what we don’t want to use it for. This technology is much like the World Wide Web’s emergence. When someone first showed me a homepage, I was like, ‘That’s never going to take off.’ And then a month and a half later, I said, ‘Well, I’ve got to build a home page.’ It’s like that, I think.”

Follow the show on Apple Podcasts, Spotify, or wherever you get your podcasts.

Here’s a transcript of the episode 3 conversation.

ELISE HU: This is WorkLab , the podcast from Microsoft. I’m your host, Elise Hu. On WorkLab , we hear from leading thinkers on the future of work—economists, designers, psychologists, technologists. They all share surprising data and explore the trends transforming the way we work. In this episode, we continue our exploration of large language model AI, or LLM AI.

JOHN MAEDA: Design today is going to play an important role in this LLM AI world, with the perspective on ethics. These kinds of ideas, which have been embedded in great products, are now going to have to be better than ever when it comes to this new kind of AI.

ELISE HU: On today’s show, John Maeda. John Maeda is a Vice President of Design and Artificial Intelligence at Microsoft, and in his richly varied career, he’s also been a professor, an author, a college president, and a business executive. His digital artwork, books, lectures, research, and teaching have explored how digital technology can empower creativity. So we have a wide-ranging chat today about this moment that we’re in for AI. So without further ado, my conversation with John Maeda.

ELISE HU: Thanks for coming on the show.

JOHN MAEDA: Glad to be here.

ELISE HU: And you recently made this big career move to join Microsoft.

JOHN MAEDA: Well, when I was in high school, I tried to apply for an internship at Microsoft and I didn’t get in. So luckily they didn’t ask me the same questions decades later, and I’m in.

ELISE HU: Well, welcome. There’s so much to talk about when it comes to AI, especially recent breakthroughs in large language models. It’s being called an inflection point. We’re hearing that a lot, or a Cambrian explosion. So why?

JOHN MAEDA: Well, I kind of chuckle when I keep reading things like inflection, Precambrian, or whatever. All these giant ways to say the whole world has shifted. I think it’s just the perfect example of the Moore’s Law effect, that the idea of doubling doesn’t seem like a big deal when it’s like one becomes two, two becomes four, four becomes eight, eight becomes 16. But the iteration, 30 or 40 of a Moore’s Law build—it’s like ketchup, the old kind of ketchup in the glass bottle where it just all plops out and you’re like, Whoa, where did this glob ketchup come from, because you’ve been holding the bottle over your head. The doubling feels very big.

ELISE HU: What are the implications?

JOHN MAEDA: Well, the implications are exciting because this technology is actually kind of useful. I think it introduces a new kind of scratch-your-head moment. Everything was command line based in the seventies and eighties: type in text and it does something for you. And then there was this graphic user interface boom, where suddenly you were able to use a mouse and use a computer. It was democratizing. Ironically, this means they’re going back to the command line, which is so interesting. But this is something that has been long foreseen, already a very common user experience pattern in China, for instance, with a WeChat world. So I think it was inevitable that we’d end up here.

ELISE HU: And when you mean that everything’s kind of returning to the command line, can you talk a little bit about that?

JOHN MAEDA: Well, I spent six years writing a book called How to Speak Machine , and the entire thesis was it’d be really good for people who don’t understand how computer science and AI works to understand the mechanics, the physics underneath it. And at the end of the book, I realized it wasn’t about how to speak machine, but how to speak human. Now we speak in natural language, English or whatever language you like. We’re speaking human to the machine.

ELISE HU: John Maeda, Wired magazine has said that Maeda is to design what Warren Buffett is to finance. I’m not going to ask you to have to, you know, respond to that particular quote, but I’d love to know, because you are so deeply embedded and considered a real leader in the designer community, how is the larger design community thinking about the potential and pitfalls of AI?

JOHN MAEDA: I feel that design today is going to play an important role in this LLM AI world, with the perspective on ethics, what matters. Trust. These kinds of ideas, which have been embedded in great products are now going to have to be better than ever when it comes to this new kind of AI. If you think of the Triangle of Engineering, product and design for technology products where, you know, product really has to carry that business role, has to make money, has to grow, preferably. And engineering is playing the role of, does it work or does it not work? Does the bridge stand by itself? Okay, it worked. Design tends to be stuck in a role where, like, is the bridge pretty enough, which is sometimes pretty important when you’re competing against other bridges. It also plays an important role in, does it look like it’s not going to fall down? And or, you know I just discovered that a certain kind of stone really is not good to take from the earth. Is this bridge made of that kind of stone? Then I actually don’t want to cross it. And I think that design cares about these dimensions. Not just the aesthetics, the beauty, but the aesthetics of the ethics inside any experience you encounter, in a way that a product person doesn’t have to care about as much and an engineer doesn’t have to care about as much. They care about it, but it isn’t in their ‘jobs to be done’ list.

ELISE HU: Huh. Well, let’s talk about some of these ethical concerns. What would you say are the questions that researchers, designers, companies grappling with AI and its potential—what needs to be worked out still most pressingly?

JOHN MAEDA: Well, there’s so many levels to that. You know, like, I’m creating the new design and tech report for South by Southwest, and I look back at the last nine years.

ELISE HU: Yeah.

JOHN MAEDA: In 2017, I noticed that Microsoft was really high-centered around responsible AI, inclusive design. And there’s one value that’s fairly simple but important, is the value of transparency, not like just see through, but do I understand it? And I think at a very basic level, understanding large language model AI, how it actually works, scientists are still trying to figure that out. But even for the general person to help them understand how it works is an important thing for design to do.

ELISE HU: How will people be able to use, beyond just these chatbots right now, but other programs to increase their creativity and their productivity?

JOHN MAEDA: Ah. In this age of AI, there’s a simple way to be less fearful of it. Ask yourself, What do you not actually like doing in your job? Like, gather all that information into a chart or summarize it for my boss. Versus, What do you want to really keep? There are things that I enjoyed doing—thinking about the strategy of something and how it might unfold. Think of ways to be able to do things 10 times faster than I ever thought possible, therefore, I can actually do 10x more. So on one hand, greater productivity because you’re doing what you are most productive and excited about. And also productivity, like, hey, I didn’t want to do that thing in the first place. So it’s all gone.

ELISE HU: I understand you have a metaphor you’ve been using, a scissors metaphor, to talk about AI. What is it?

JOHN MAEDA: Oh, well, you know, I held on to this thing from my early days of trying to understand artificial intelligence in the eighties. This work, from a person named Herbert Simon, he’s a Carnegie Mellon AI legend, but interestingly, he received a Nobel Prize in economics. And he had this phrase that always stuck with me about how the way to think of intelligence is, it’s two blades of a scissor. One blade of the scissors is cognition, and the other blade is context. And when you slice, slice, slice those two together, rub them together, it creates what feels like intelligence, which is what’s happened with large language model AI.

ELISE HU: It’s not just cognition that computers can handle now, it’s context.

JOHN MAEDA: Well, this amazing cognition blade arrived. And now we can just, like, rub context against it. Like, I could take the last eight things we said to each other—the context—rub it against the cognition blade and say, Hey, what did we talk about?

ELISE HU: Yeah, sum up the themes of our conversation.

JOHN MAEDA: It does that. A cognition blade is like, ready to go, boss. And the context is just pouring our information on top of it. And voila.

ELISE HU: Is AI capable of creativity itself, or does it just facilitate human creativity?

JOHN MAEDA: The best way I’ve heard this technology described is, it’s like a parrot, but it’s an awfully good parrot. It doesn’t just repeat back things you said to it, it can repeat back things that a lot of people in the world have said. So is it creative on its own? No. Can it make you more creative? Well, the answer is, every time you expose yourself to new information, do you get more creative? Yeah. So it’s a way to accelerate your own creativity.

ELISE HU: Well, we are asking a variety of people like you, experts in their field, as well as civilians, how they’re using AI in just their everyday lives. So what is it for you?

JOHN MAEDA: Well, as you discover how to leverage this odd technology, you find that, wow, that’s easy. Like, I always use Python, the programming language Python, to do things fast. Like, oh, I’ve got to sort this document this way, I’m going to write a Python code or whatever. Now, I just give it to the model and say, Hey, this is all the stuff I have, the context. Can you now categorize these things? And it’s like magic, voila. Or I’m trying to figure this thing out and I want 10 different perspectives, so can you be someone who’s a botanist? Can you be someone who is a shopkeeper? So it’s like running user research studies very quickly.

ELISE HU: Yeah.

JOHN MAEDA: With fictional people, they’re better than a persona, actually. You can talk with them.

ELISE HU: Oh, that’s interesting. Do you have kind of a dream scenario for where things look two to five years from now?

JOHN MAEDA: I think that we’re already seeing elements of how this model-based work that we do, whether the model is language-based or it’s image-based or interaction-based, it’s going to affect how we do things. When we make images or image with text or video, basically everything we do to communicate, I think it’s going to make it a lot easier for us to do the part that we usually only do if we’re not tired, you know? I mean, how many things have you made where you’re like, Oh my gosh, all this planning, here I go, do it. Okay, I did it. Well, I’m really tired. I don’t know what it’s going to be like, but I feel like I’m going to do the part that I actually thought I should be doing at the very end, but I got too tired.

ELISE HU: I feel like it could increase our body of knowledge too, right, to be able to see so many things in different ways or look around the corners that we were too tired to look around.

JOHN MAEDA: Oh, 100 percent. This whole list of things that we can do better, that I keep asking myself, What do I not like to do now? What can I Marie Kondo out of my brain? And now what if I had more time? What would I do instead?

ELISE HU: Yeah. Okay, so let’s talk a little bit about leaders of organizations and leadership. What should leaders, or what could they do, to harness this potential of AI, not just for themselves, but also for their teams?

JOHN MAEDA: I think what’s really powerful for leaders is the ability to listen broadly. Because the only way for leaders to listen right now, generally speaking, is through one-on-ones, which do not scale.

ELISE HU: Those are just their lieutenants, though, right? It’s not a foot soldier.

JOHN MAEDA: Well, you know, the good leaders skip levels and actually break the rules and, like, talk to everyone. I like those kinds of leaders because it creates individual bonds of trust, which means the organization can usually move faster because of that. However, it takes a lot of time. So, ultimately, you have the other choice, which is surveys. As we know, the best part of those surveys is the fill-in-the-blank part. In the past we only had word clouds, but now, bosses can talk to all of that feedback and say, Tell me about the time I let you all down. Tell me about the time that you felt really proud to be here. So it’s like doing Q&A, 24/7.

ELISE HU: Yeah. And the potential for being able to take those learnings and apply them, or change direction or come up with a new vision, are really endless.

JOHN MAEDA: It basically lets them save time to do the part that they probably were hired to do, but they could never do because the logistics of being able to communicate through a hierarchy are tremendous, as you know.

ELISE HU: Okay. More broadly, John, you have spoken a lot on what corporations and corporate leaders can learn from entrepreneurs or more scrappy start-ups. What can they learn?

JOHN MAEDA: I felt that there are these start-up companies and there are the grown-up companies. And the irony is that start-ups want to end up like the grown-ups, but, you know, the grown-ups are always like, Gee, I wish I was a start-up again. So I think that both can learn from each other. But the biggest thing one can learn from an entrepreneur is proximity to the customer, because it’s like a car with no walls, barely wheels. It’s got a jagged steering wheel. It’s like, Ouch. And the customer’s like, hey, I don’t like this, all the time. Whereas if you’re in a large corporation, you’re kind of like in an SUV or a bus or a jumbo jet. And so you really can’t feel the customer and how they are experiencing what you’re providing to them. So, learn from entrepreneurs how to listen to the customer, and that goes to the beauty of these new LLM AI systems. It means that the CEO or any different level of a corporation can actually begin to talk with customers, effectively, 24/7—understand what they’re thinking from all the customer support data that they get, which if I were a customer support professional, I would think, Wow, thank goodness it’s not just me hearing this. It’s my boss, my boss’s boss, my boss’s boss. Entrepreneurs are great with customers and that’s where they’ll learn.

ELISE HU: Okay, so for the listeners out there who are excited about the potential of AI and a lot of the things that we have talked about, where should they start?

JOHN MAEDA: Well, they should first start by trying this stuff out. I think that I have presented to a variety of audiences of all sizes, and I’ll ask, Hey, you know, who’s used this thing, ChatGPT, before? Who uses it every day? Like, who’s never heard of it? And ultimately, there are those who have not heard of it. The second thing is to break that transparency barrier, because what people are afraid of is they don’t really understand it at all. I like to point out that the only letter you have to care about in C-H-A-T G-P-T is the P. The P stands for pre-trained . So what that means is you’re getting out-of-the-box, powerful machine learning. As you know, in the old days, the only way to get AIML was to have a lot of data, because you had to train it. What’s different this time is, it comes pre-trained. It’s like a puppy that arrives, like able to do everything. And so you’re freaked out. You’re like, Whoa, this AI comes pre-trained? And then once you get over that cognitive hurdle, you discover it can do a lot of things you didn’t expect. And so, try it out. Learn from it. Learn how prompts work, learn how context works. Take the scissor blades and start snip, snip, snipping. I think the other thing that’s actionable is to help everyone in their organization understand that change is always a scary thing. And this is a change that really is a giant blob of ketchup coming out, maybe the whole bottle came out all at once. And so the next reaction is like, Hey, I don’t like ketchup. Ketchup is not good for you. You know, that kind of feeling. And so every organization should ask the question. Let’s first understand it. Let’s try it. Let’s learn what the cons list are, like, pros and cons. Let’s look at the pros and just kind of adapt as quickly as possible to what we want to use and what we don’t want to use. Because this technology is much like the world wide web’s emergence. I’m not sure if you were like me, but when someone showed me a homepage, I was like, Nah, never going to take off. Like a month and a half later, well, gotta build a homepage. So it’s like that, I think.

ELISE HU: John, you mentioned that you are neuroatypical, and so many folks out there are. So I’d love to know what potential you see for AI and accessibility.

JOHN MAEDA: Well, I like the fact that I can talk to it and share things, and I can ask it, Hey, can you make that more sense to the majority of people? And I think that it is a wonderful translator and interpreter of things. I’m also high on the autistic spectrum, so sometimes I can’t read emotion very well. So I can ask it to tell me, like, what does this mean? Like what’s the downlow? And that’s extremely helpful.

ELISE HU: I love that. Okay. Thanks so much.

JOHN MAEDA: Well, thanks for having me.

ELISE HU: Thanks again to John Maeda. I loved that conversation. And that’s it for this episode of the WorkLab podcast from Microsoft. Please subscribe and check back for the next episode. If you’ve got a question you’d like us to pose to leaders, drop us an email at worklab@microsoft.com. And check out the WorkLab digital publication, where you will find transcripts of all our episodes, along with thoughtful stories that explore the ways we work today. You can find all of it at Microsoft.com/WorkLab. As for this podcast, please rate us, review, and follow us wherever you listen. It helps us out. The WorkLab podcast is a place for experts to share their insights and opinions. WorkLab is produced by Microsoft with Godfrey Dadich Partners and Reasonable Volume. I’m your host, Elise Hu. Mary Melton is our correspondent. Sharon Kallander and Matthew Duncan produced this podcast. Jessica Voelker is the WorkLab editor. Okay, until next time.

The author and professor offers science-based tips for work wellbeing—and a glimpse at how AI might help

What leaders must do to harness the full potential of the coming AI revolution